<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Docker学习笔记（5）- 端口映射与容器互联]]></title>
    <url>%2F2018%2F03%2F29%2FDocker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89-%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E4%B8%8E%E5%AE%B9%E5%99%A8%E4%BA%92%E8%81%94%2F</url>
    <content type="text"><![CDATA[端口映射与容器互联除了通过网络访问外，Docker还提供了两个很方便的功能来满足服务访问的基本需求：一个是允许映射容器内应用的服务端口到本地宿主主机；另一个是互联机制实现多个容器间通过容器名来快速访问。 端口映射实现访问容器从外部访问容器应用在启动容器的时候，如果不指定对应的参数，在容器外部是无法通过网络来访问容器内的网络和服务的。 当容器中运行一些网络应用，要让外部访问这些应用时，可以通过-P或-p参数来指定端口映射。 当使用-P标记时，Docker会随机映射一个49000~49900的端口到内部容器开放的网络端口。 映射所有接口地址hostPort:containerPort：将本地的5000端口映射到容器的5000端口 此时会绑定本地所有接口上的所有地址，多次使用-p标记可以绑定多个端口。 映射到指定地址的端口ip::containerPort：映射到指定地址的任意的端口： 使用 ip::containerPort 绑定 localhost 的任意端口到容器的 5000 端口，本地主机会自动分配一个端口。 映射到指定地址的端口当使用-p 标记时 则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 ： ip:hostPort:containerPort ：指定映射使用一个特定地址，比如localhost地址127.0.0.1: 查看映射端口配置使用docker port命令来查看当前映射的端口配置，可以查看到绑定的地址。 $ docker port &lt;container_id | container_name&gt; 注意：容易有自己的内部网络和IP地址，使用docker inspect + 容器Id可以获取容器的具体信息。 互联机制实现便捷访问容器的互联（linking)是一种让多个容器中应用进行快速交互的方式。他会在源和接收容器之间创建连接关系，接收容器可以通过容器名快速访问到容器源，而不用指定具体的IP地址。 自定义容器命名连接系统依据容器的名称来执行。因此需要定义一个好记的容器的名字。 虽然当创建容器的时候，系统会默认分配一个名字，单自定义容器名字有两个好处： 自定义命名比较好记，比如一个Web容器，我们可以起名为web，一目了然； 当要连接其他容器时，即便重启，也可以使用容器名而不用改变，比如web容器连接到db容器。 使用–name标记可以为容器自定义命名： 使用docker inspect命名查看 注意： 容器的名称是唯一的。如果已经命名了一个叫web的容器，当你要再次使用web这个名称的时候，需要先用docker rm来删除之前创建的同名容器。 在执行docker run的时候，如果添加–rm标记，则容器在终止后会立刻删除。注意，–rm和-d参数不能同时使用。 容器互联使用–link参数可以让容器之间安全地进行交互。 下面先创建一个新的数据库容器 查看创建的容器信息 然后创建一个新的web容器，并将它连接到db容器 此时，db容器和web容器建立互联关系 –link参数的格式为–link name:alias，其中name是要连接的容器名称，alias是这个连接的别名。 使用docekr ps来查看容器的连接，如下图所示： Docker相当于在两个互联的容器之间创建了一个虚机通道，而且不用映射他们的端口到宿主主机上。在启动db容器的时候并没有使用-p和-P标记，从而避免了暴露数据库服务端口到外部网络上。 Docker通过两种方式为为容器公开连接信息： 更新环境变量； 更新/etc/hosts文件。 使用env命名来查看web容器环境变量： 其中DB_开头大写的环境变量是供web容器连接db容器使用的，前缀采用大写的连接别名。 除了环境变量之外，Docker还添加host信息到父容器的/etc/hosts文件。下面是父容器web的hosts文件： 这里有两个hosts信息，第一个是web容器，web容器用自己的id作为默认主机名，第二个是容器的ip和容器的别名以及id。 可以在web容器中安装Ping命令来测试与db容器的连通： 用Ping来测试db容器，他会解析成172.17.0.5。用户可以连接多个子容器到父容器，比如可以连接多个web到同一个db容器上。 本文小结毫无疑问，容器服务的访问是很关键的一个用途。本文通过具体案例讲解了Docker容器服务访问的两大基本操作，包括基础的容器端口映射机制和容器的互联机制。同时，Docker目前可以成熟的支持Linux系统自带的网络服务和功能，这既可以利用现有成熟的技术提供稳定支持，又可以实现快速的高性能转发。 在生产环境中，网络方面的需求更加复杂多变，包括跨主机甚至夸数据中心的通信，这时候往往就需要引入额外的机制，例如SDN或NFV（网络功能虚拟化）的相关技术。]]></content>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker学习笔记（4）- Docker数据卷]]></title>
    <url>%2F2018%2F03%2F29%2FDocker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89-Docker%E6%95%B0%E6%8D%AE%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[Docker数据卷生产环境中使用Docker的过程中，往往需要对数据进行持久化，或者需要在多个容器之间进行数据共享，这必然涉及容器的数据管理操作。 容器中管理数据主要有两种方式： 数据卷(Data Volume)：容器内数据直接映射到本地主机环境； 数据卷容器(Data Volume Containers)：使用特定容器维护数据卷。 本文将首先介绍如何在容器内创健数据卷，并且把本地的目录或文件挂载到容器内的数据卷中。接下来会介绍如何使用数据卷容器在容器和主机、容器和容器之间共享数据，并实现数据的备份和恢复。 数据卷数据卷是一个可供容器使用的特殊目录，它将主机操作系统目录直接映射进容器，类似于Linux中的mout操作。 数据卷可以提供很多有用的特性，如下所示： 数据卷可以在容器之间共享和重用，容器间传递数据将变得高效方便； 对数据卷内数据的修改会立马生效，无论是容器内操作还是本地操作； 对数据卷内数据的修改会立马生效，无论是容器内操作还是本地操作； 对数据卷的更新不会影响到镜像，解耦了应用和数据； 卷会一直存在，只有没有容器使用，可以安全地卸载它。 在容器中创建一个数据卷在用docker run命令的时候，使用-v参数可以在容器内创建一个数据卷。多次重复使用-v标记可以创建多个数据卷。 使用图中的命令在镜像ubuntu:latest上创建一个在后台运行名为volume_test的容器，并且创建了一个名为/data_volume的数据卷。 进入容器查看，已经有了data_volume目录 挂载一个本地目录作为数据卷下面的命令创建了一个容器，并且将容器中的数据卷/data_valume挂载到本地/Users/xiangqilin/docker/data_volume。 进入容器，在数据卷/data_volume中创建一个文件test，然后在本地/Users/xiangqilin/docker/data_volume查看，容器中数据卷的数据已经映射到了本地。 挂载数据卷的默认权限为读写（rw）,可以将其改为只读（ro)。 只需要在加上ro参数，如下所示： 挂载一个本地文件作为数据卷（不推荐）用下面的命令可以挂载一个文件到本地，记录容器中执行的bash命令。 注意： 如果直接挂载一个文件倒容器，使用文件编辑工具，包括vi或者sed –in-place的时候，可能会造成文件inode的改变，从Docker 1.1.0起，这会导致报错信息。所以推荐的方式是直接挂载该文件所在的目录。 数据卷容器如果用户需要在多个容器之间共享一些持续更新的数据，最简单的方式是使用数据卷容器。数据卷容器也是一个容器，但是它的目的是专门用来提供数据卷供其他容器挂载的。 首先创建一个数据卷容器volume_container，并在其中创建一个/db_data 创建一个容器db1，挂载volume_container中的数据卷/db_data,使用ls可以看到根目录下已经有了db_data 创建一个容器db2，挂载volume_container中的数据卷/db_data，使用ls可以看到根目录下已经有了db_data 下面的代码将测试数据卷容器挂载的目录是否在各个容器之间是同步的： 第一步在数据卷容器的数据卷中创建一个test文件。 第二步在db1容器中，查看其挂载的数据卷，是否有test文件。 可以看到容器db1的挂载的数据卷中已经有了test文件，说明被挂在的数据卷容器中的数据卷和挂载数据卷是同步的。 进一步验证，我们将在容器db1挂载的数据卷中创建一个文件，然后验证db2中是否也存在： 可以看出，在容器db1中的挂载数据卷中创建的test2文件，已经同步到了db2的挂载数据卷中，所以只要是挂载的同一数据卷容器的数据卷，那么他们之间都是同步的。 可以多次使用--volumes-from参数来从多个容器挂载多个数据卷。还可以从其他已经挂载了容器卷的容器来挂载数据卷。 注意： 使用--volume-from参数所挂载数据卷的容器自身并不需要保持在运行状态。 如果删除了挂载的容器（volume_container、db1和db2），数据卷并不会被自动删除。如果要删除一个数据卷，必须在删除最后一个还挂载着他的容器时显示使用docker rm -v命令来指定同时删除关联的容器。 利用数据卷容器来迁移数据可以利用数据卷容器对其中的数据卷进行备份、恢复，以实现数据的迁移。下面介绍这两个操作。 备份使用下面的数据来备份数据卷db_data 这个命令有点复杂，分析一下：首先创建一个ubuntu镜像的容器，然后挂载数据卷容器volume_container的数据卷db_data。然后把自身容器中/backup目录挂载到本地/Users/xiangqlin/docker/backup。容器启动后，执行tar -cvf /backup/backup.tar /db_data将挂载的数据卷/db_data压缩到/backup/backup.tar。因为/backup目录被挂载到了本地，所以在本地也备份了数据卷的数据。 恢复]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker学习笔记（3）- Docker仓库]]></title>
    <url>%2F2018%2F03%2F29%2FDocker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89-Docker%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[访问Docker仓库仓库（Repository）是集中存放镜像的地方，分公共仓库和私有仓库。一个容器混淆的概念是注册服务器（Registry)。实际上注册服务器是存放仓库的具体服务器，一个服务器上可以有多个仓库，而每个仓库下面可以有多个镜像。从这方面来说，可以将仓库看做一个具体的项目和目录。例如对于仓库地址private-docker.com/ubuntu来说，private-docker.com是注册服务器地址，ubuntu是仓库名。 Docker Hub公共镜像市场目前Docker官方维护了一个公共镜像仓库http://hub.docker.com，其中包括超过15000个镜像。大部分镜像需求，都可以通过在Docker Hub中直接下载镜像来实现。 登录docker login命令来输入用户名、密码登录。 基本操作用户无需登录即可通过docker search命令来查找官方仓库中的镜像，并利用docker pull命令来下载到本地。 根据是否为官方提供，可将这些镜像资源分为两类。一种是类似centos这样的基础镜像，成为基础或根镜像。这些镜像是由Docker公司创建、验证、支持、提供。这样的镜像往往使用单个单词名字。 还有一种类型，比如ansible/centos7-ansible镜像，它是由用户ansible创建并维护的，带有用户名为前缀，表明是用户下的某仓库。可以通过用户名称前缀user_name/镜像名称来指定使用某个用户提供的镜像。 另外在查找的时候，通过-s N参数可以指定显示评价为N星以上的镜像。 下载centos镜像到本地，如下所示： 用户也可以通过docker push命令来将本地镜像推送到Docker Hub。 提示：Ansible是知名自动化部署配置管理工具。 自动创建自动创建（Automated Builds）功能对于需要经常升级镜像内程序来说，十分方便。有时候，用户创建了镜像，安装了某个软件，如果软件版本发布新版本则需要手动跟新。 而自动创建允许用户通过Docker Hub指定跟踪一个目标网站（目前支持GitHub或BitBucket)上的项目，一旦项目发生新的提交，则自动执行创建。 要配置自动创建，包括如下的步骤： 创建并登陆Docker Hub，以及目标网站；并在目标网站中链接账户到Docker Hub； 在Docker Hub中配置一个“自动创建”； 选取一个目标网站中的项目（需要含Dockerfile）和分支； 指定Dockerfile位置，并且提交创建 搭建本地仓库使用registry镜像创建私有仓库安装docker后，可以通过官方提供的registry镜像来简单搭建一套本地私有仓库环境： $docker run -d -p 5000:5000 regitry 这将自动下载并启动一个registry容器，创建本地的私有仓库服务。 默认情况下，会将仓库创建在容器的/tmp/registry目录下。可以通过-v参数来将镜像文件夹存放在本地的指定路径，例如下面的例子将镜像放到/Users/xiangqilin/registry 注意registry:2是ash shell，如果执行$docker exec -it nifty_mahavira /bin/bash会报错 向搭建好的本地仓库push成功之后，-v参数指定的映射目录也会存储上传的镜像]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker学习笔记（2）- Docker容器]]></title>
    <url>%2F2018%2F03%2F29%2FDocker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89-Docker%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[docker容器容器是Docker一个核心概念。简单来说，容器是镜像的一个运行示例。所不同的是，镜像是静态的只读文件，而容器带有运行时需要的可写层文件。如果认为虚拟机是模拟运行的一整套操作系统（包括内核、应用运行态环境和其他系统环境）和跑在上面的应用，那么Docker容器就是独立运行的一个（或一组）应用，以及他们必要的运行环境。 创建容器新建容器可以使用docer create命令新建一个容器，例如： 使用docker create命令新建的容器处于停止状态，可以使用docker start命令来启动它。 create命令和run命令支持的选项都十分复杂，主要包括如下几大类： 与容器运行模式相关 与容器和环境配置相关 与容器资源限制和安全保护相关 表1 create命令与容器运行模式相关的选项 表2 create命令与容器环境和配置相关的选项 表3 create命令与容器资源限制和安全保护相关的选项 其他还比较重要的选项： -l, --label=[]：以键值对方式指定容器的标签信息 --label-file=[]：从文件中读取标签信息 启动容器使用docker start命令来启动一个已经创建的容器，例如启动刚才创建的容器 可以看出 $docker start aae命令启动了刚才状态为created的容器，参数aae是该容器id的前三个字符，说明只要可以唯一区别一个容器，id可以简写。 新建并启动容器除了创建容器后通过start命令来启动，可以直接新建并启动容器。所需要的命令主要为docker run，等价于docker create命令，在执行docker start命令。 用下面的命令启动一个容器，并在容器中打印“docker run test” 查看容器，可以发现，执行完命令之后，就退出了，状态变为exited 当利用docker run来创建并启动容器时，Docker在后台运行的标准操作标准包括： 检查本地是否存在指定的镜像，不存在就从共有仓库下载 利用镜像创建一个容器，并启动该容器 分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中 从网桥的地址池配置一个IP地址给容器 执行用户指定的应用程序 执行完毕后容器被自动终止 下面的命令创建并运行了一个容器，还启动了一个bash终端，允许和用户交互 其中-t选项让Docker分配了一个伪终端（pseudo-tty）并绑定到容器的标准输入上，-i则让容器的标准输入保持打开。下面用ps命令来查看进程，只有bash和ps命令，没有其他进程。最后用exit命令退出或者ctrl+d 某些时候，执行docker run会出错，因为命令无法正常执行容器会直接退出，此时可以查看退出的错误代码。 默认情况下，常见错误代码包括： 125：Docker daemon执行出错，例如指定不支持的Docker命令参数； 126：所指定的命令无法执行，例如权限出错。 127：容器内命令无法找到 命令执行出错后，会默认返回错误码。 守护态运行守护进程：守护进程是一个在后台运行并且不受任何终端控制的进程。Unix操作系统有很多典型的守护进程(其数目根据需要或20—50不等)，它们在后台运行，执行不同的管理任务。 —-百度 更多的时候，需要让Docker容器在后台以守护态（Daemonized）形式运行。此时，可以通过添加-d参数来实现。 例如下面的命令会在后台容器运行： 此时，要获取容器的输出信息，可以如下使用docker logs命令： 终止容器可以使用docker stop来终止一个运行中的容器。该命令格式为 $docker stop [-t | --time[=10]][CONTAINER…] 首先向容器发送SIGTERM信号，等待一段超时时间（默认10秒）后，再发送SIGKILL信号来终止容器 注意： docker kill命令会直接发送SIGKILL信号来强行终止容器。 此外，当Docker容器中指定的应用终结时，容器也会自动终止。例如对于上一节中只启动了一个终端的容器，用户通过exit命令或Ctrl+D来退出终端时，所创建的容器立刻终止，处于exited状态。 可以通过start命令来使终止态的容器重新启动 可以使用restart命令先终止容器，再重新启动。 进入容器在使用-d参数时，容器启动后会进入后台，用户无法看到容器中的信息，也无法进行操作。 这个时候如果需要进入容器进行操作，有多种方法，包括官方的attach或exec命令，以及第三方的nsenter工具等。 attach命令attacn是docker自带的命令，命令格式为： docker attach [--detach-keys[=[]]][--no-stdin] [--sig-proxy[=true]] CONTAINER 支持三个主要选项： --detach-keys=[=[]]：指定退出attach模式的快捷键序列，默认为CTRL-P,CTRL-Q; --no-sdtin=true|false：是否关闭标准输出，默认是保持打开的； --sig-proxy=true|false：是否代理收到的系统信号给应用进程，默认为true。 但是有时候使用attach命令并不方便。当多个窗口同时用attach命令连到同一个容器时，多有窗口都会同步显示。当某个窗口因为命令阻塞时，其他窗口也无法执行操作了。 exec命令Docker从1.3.0.版本起提供了一个更加方便的exec命令，可以在容器内直接执行任意命令。 docker exec [-d|--detach][--detach-key[=[]]] [-i|--interactive][—privileged] [-t|--tty][-u|--user[=USER]] CONTAINER COMMAND [ARG…] 比较重要的参数： -i, --interactive=true|false：打开标准输入接受用户输入命令，默认为false； --privileged=true|false：是否给执行命令以高权限，默认为false； -t, --tty=true|false：分配伪终端，默认为false。 -u, --user=&quot;&quot;：执行命令的用户或id 例如进入刚才的容器，并启动一个bash： 从上面可以看出，只能在一个运行的容器才能使用exec命令； 先启动容器，在执行exec命令： 可以看到，一个bash终端打开了，在不影响容器内其他应用的前提下，用户可以很容易与容器进行交互。 注意：通过指定-it参数来保持标准输入打开，并且分配一个伪终端。通过exec命令对容器执行操作是最为推荐的方式。 nsenter工具 删除容器可以使用docker rm命令来删除处于终止或退出状态的容器，命令格式为 docker rm [-f|--force][-l|--link] [-v|--volumes] CONTAINER[CONTAINER…] 主要支持的选项包括： -f, --force=false：是否强制终止并删除一个运行中的容器； -l, --link=false：删除容器的链接，但保留容器； -v, --volumes=false：删除容器挂载的数据卷。 例如，查看处于终止状态的容器，并删除： 默认情况下，docker rm命令只能删除处于终止或退出状态的容器，并不能删除还处于运行状态的容器。 如果直接删除一个运行中的容器，可以添加-f参数。Docker会先发送SIGKILL信号给容器，终止其中的应用，之后强行删除，如下所示： 导入和导出容器某些时候，需要将容器从一个系统迁移到另外一个系统，此时可以使用Docker的导入和导出的功能。这也是Docker自身提供的一个重要的特性。 导出容器导出容器是指导出一个已经创建的容器到一个文件，不管此时这个容器是否处于运行状态，可以使用 $docker export命令，该命令的格式为： $docker export [-o|--output[=&quot;&quot;]]CONTAINER。其中，可以通过-o选项来指定导出的tar文件名，也可以通过重定向来实现。 下面分别使用-o参数和重定向的方式导出容器： 时候可以将导出的tar文件输出到其他的机器上，然后再通过导入命令导入到系统中，从而实现容器的迁移。 导入容器导出的文件又可以使用docker import命令导入变成镜像，该命令格式为： docker import [-c|--change[=]]][-m|--message[=MESSAGE]] file|URL|-[REPOSITORY[:TAG]] 可以通过-c, --change=[]选项在导入的同时执行对容器进行修改的Dockerfile指令。 也可以使用docker load命令来导入镜像存储文件到本地镜像库，也可以使用docker import命令来导入一个容器快照到本地镜像库。 这两者的区别在于容器快照文件将丢失所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也更大。此外，从容器快照导入时可以重新定义标签等元数据。 exported-imported和saved-loaded的区别 导出后再导入(exported-imported)的镜像会丢失所有的历史，而保存后再加载（saveed-loaded）的镜像没有丢失历史和层(layer)。这意味着使用导出后再导入的方式，你将无法回滚到之前的层(layer)，同时，使用保存后再加载的方式持久化整个镜像，就可以做到层回滚（可以执行docker tag 来回滚之前的层）。–百度 小结 容器是直接提供应用服务的组件，也是docker实现快速启停和高效服务性能的基础。 命令小结create start restart run stop attach exec rm export -————- 导入和导入镜像一样： import–export save—-load 再生产环境中，因为容器自身的轻量级特性，推荐使用容器时在一组容器前引入HA(High Availability，高可靠性）机制。例如使用HAProxy工具来代理容器访问，这样在容器出现故障时，可以快速切换到功能正常的容器。此外，建议通过指定合适的容器重启策略，来自动重启退出的容器。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker学习笔记（1）- Docker镜像]]></title>
    <url>%2F2018%2F03%2F29%2FDocker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89-Docker%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[获取镜像$docker pull NAME[:TAG] 如果不加TAG则表示下载最新的镜像，一个镜像由“名称”+“标签决定” 使用不同镜像仓库服务器情况下，可能会出现镜像重名： 严格的将，镜像的仓库名称中还应该添加仓库地址（即registry，注册服务器）作为前缀，如果使用Docker Hub服务，该前缀可以忽略。 即：$docker pull ubuntu:14.04相当于$docker pull registry.hub.docker.com/ubuntu:14.04 pull子命令： -a, --all-tags=true|false：是否获取仓库中的所有镜像，默认为否。 使用镜像：例如利用该镜像创建一个容器，在其中运行bash应用，执行ping localhost: $docker run -it unbuntu[:TAG] bash root@f46310567509:/# ping localhost 如果提示command not found，则 $apt-get update $apt-get install iputils-ping 详细见：http://blog.csdn.net/silentwolfyh/article/details/52336007 查看镜像信息docker images [OPTIONS][REPOSITORY[:TAG]] OPTIONS说明： -a :列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层）； —digests :显示镜像的摘要信息； -f :显示满足条件的镜像； —format :指定返回值的模板文件； --no-trunc :显示完整的镜像信息； -q :只显示镜像ID。 使用docker images命令列出镜像 镜像的仓库：ubuntu的系列镜像由ubuntu仓库保存 标签 镜像ID，镜像的唯一标识 创建的时间，说明镜像最后跟新时间 镜像大小 镜像标签使用tag命令添加镜像标签，可以发现多了一个myubuntu:latest标签，其id和ubuntu:latest是一样的，其实他们都指向同一个镜像，只是别名不同，标签相当于起到了链接的作用。 查看镜像详细信息使用docker inspect命令查看详细信息，包括制作者、适应架构、各层的数字摘要等： 输出一个json文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394[ &#123; "Id":"sha256:8b72bba4485f1004e8378bc6bc42775f8d4fb851c750c6c0329d3770b3a09086", "RepoTags":[ "myubuntu:latest", "ubuntu:latest" ], "RepoDigests":[ "ubuntu@sha256:2b9285d3e340ae9d4297f83fed6a9563493945935fc787e98cc32a69f5687641" ], "Parent":"", "Comment":"", "Created":"2017-09-13T03:58:50.383839319Z", "Container":"ee87d884293ece0d9fa040a43ffb75097264185f94437a0d1fc2ddfd3c82ca4b", "ContainerConfig":&#123; "Hostname":"ee87d884293e", "Domainname":"", "User":"", "AttachStdin":false, "AttachStdout":false, "AttachStderr":false, "Tty":false, "OpenStdin":false, "StdinOnce":false, "Env":[ "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" ], "Cmd":[ "/bin/sh", "-c", "#(nop) ", "CMD ["/bin/bash"]" ], "ArgsEscaped":true, "Image":"sha256:5bf9c8f025cb9bdfec431fbf2a39e1d25117a94ce2b10db01db9630addfc5e37", "Volumes":null, "WorkingDir":"", "Entrypoint":null, "OnBuild":null, "Labels":&#123; &#125; &#125;, "DockerVersion":"17.06.2-ce", "Author":"", "Config":&#123; "Hostname":"", "Domainname":"", "User":"", "AttachStdin":false, "AttachStdout":false, "AttachStderr":false, "Tty":false, "OpenStdin":false, "StdinOnce":false, "Env":[ "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" ], "Cmd":[ "/bin/bash" ], "ArgsEscaped":true, "Image":"sha256:5bf9c8f025cb9bdfec431fbf2a39e1d25117a94ce2b10db01db9630addfc5e37", "Volumes":null, "WorkingDir":"", "Entrypoint":null, "OnBuild":null, "Labels":null &#125;, "Architecture":"amd64", "Os":"linux", "Size":120102168, "VirtualSize":120102168, "GraphDriver":&#123; "Data":&#123; "LowerDir":"/var/lib/docker/overlay2/579119ec0ba94ba9c2b510b75228f366c14fc1a29302f29a7c915946f9038c54/diff:/var/lib/docker/overlay2/2286560d99b26f3e25b0cb65f100915b2bf3848ff483b2b46f036a782fe92e87/diff:/var/lib/docker/overlay2/90c4f96886f317dfc958dededefa77f9a648011b7002e42c458b61022e950ab9/diff:/var/lib/docker/overlay2/fba0d170b11c979215b1fe227f86b3499427f1908f3f70dbddde2f94d433ee77/diff", "MergedDir":"/var/lib/docker/overlay2/95395204f6fdd03d04da60ee7d1c1e7ff4bf7e96eb789eca0cdeedf58125aecb/merged", "UpperDir":"/var/lib/docker/overlay2/95395204f6fdd03d04da60ee7d1c1e7ff4bf7e96eb789eca0cdeedf58125aecb/diff", "WorkDir":"/var/lib/docker/overlay2/95395204f6fdd03d04da60ee7d1c1e7ff4bf7e96eb789eca0cdeedf58125aecb/work" &#125;, "Name":"overlay2" &#125;, "RootFS":&#123; "Type":"layers", "Layers":[ "sha256:8aa4fcad5eeb286fe9696898d988dc85503c6392d1a2bd9023911fb0d6d27081", "sha256:ebf3d6975c708f538b14a5267afd2c4c64e8243d195aa11d878e566a7e64c727", "sha256:a76db6d8fac422acd5fb6c28166c906c202639e4e833cf88c7d4965b806c5437", "sha256:cd1d6655b4e44bb95df75bd2ecde4ad6799dd23337a9dedadf6e0b7f0efdc27e", "sha256:3996d0debc49f9a96c25d4ab7a5c9e824229c09976551b80ab0da70fa993a10d" ] &#125; &#125;] 可以使用-f参数来指定获取某一项参数： 参考http://www.cnblogs.com/boshen-hzb/p/6376674.html 镜像历史使用history命令查看镜像历史。 镜像文件由多个层组成，可以用history命令，显示各层的创建信息。 搜寻镜像使用docker search命令可以搜索远端仓库中共享的镜像，默认搜索官方仓库总的镜像。用法为docker search TERM，支持的主要参数包括： --automated=true|false:仅显示自动创建的镜像，默认为否 --no-trunc=true|false:输出信息不截断显示，默认为否 -s, --stars=X：指定仅显示评价为指定星级以上的镜像，默认为0，即输出所有镜像。 例如，搜索所有自动创建的3星级以上的带 nginx关键字的镜像: 删除镜像使用docker rmi命令可以删除镜像，命令格式为docker rmi IMAGE [IMAGE]，其中IMAGE可以为标签或ID。 例如，要删除掉myubuntu:latest镜像，可以使用如下命令 可以看出，如果一个镜像有多个标签，只会删除多个标签中指定的标签而已，镜像不会受影响。 如果某个镜像只有一个标签时，则要注意，删除标签就会删除镜像。 现在只有一个标签，然后尝试删除镜像： 删除失败，因为有容器还在镜像上面运行 可以使用docker ps -a命令查看本机上的所有容器： 可以看出有容器在镜像上运行，所以不能直接删除，当然可以使用命令 $docker rmi -f ubuntu:latest来强制删除，但是不建议这样做，建议先删除容器，然后删除镜像： 我们先使用-f参数来删除httpd镜像： 但是发现镜像依然存在 再次使用$docker ps -a命令来查看容器，发现仍然有容器运行 所以并不推荐使用-f参数来强制删除，下面是正确的步骤，先删除运行在镜像上面的容器，然后再删除镜像。 现在先使用$docker rm CONTAINER_ID删除容器，有一个错误， 可以看出id为a420…的容器还在运行，所以不能删除，使用$docker ps -a查看删除情况， 状态为未运行的容器已经删除，然而运行状态的并没有删除 所以现在需要先使用$docker stop CONTAINER_ID停止运行的容器 可以看出id为a420…的容器状态已经改变，现在可以删除了 可以看出，容器已经被删除了，现在就可以去删除httpd镜像了： 使用$docker rmi IMAGE_ID删除镜像，然后使用$docker images查看删除情况，可以看出httpd镜像已经全部删除完了。 一次性删除所有容器 创建镜像创建镜像的方法主要有三种： 基于已有镜像的容器创建 基于本地模板导入 基于Dockerfile创建 这里主要介绍前两种方法，第三种方法后续学习笔记介绍。 基于已有镜像的容器创建主要使用docker commit命令。命令格式为 docker commit [OPTIONS] CONTAINER [REPOSITORY [:TAG]] ​ 所基于的容器 创建的镜像的标签 主要的选项包括： -a, author=&quot;&quot;：作者信息 -c, --change=[]：提交的时候执行Dockerfile命令，包括CMD|ENTRYPOINT|ENV|EXPOSE|LABEL|USER|VOLUME|WORKDIR等 -m, --message=&quot;&quot;：提交消息 -p, --pause=true：提交时暂停容器运行 下面演示怎么根据已有镜像的容器创建一个新的镜像。 首先启动一个镜像，然后进行进行一些操作，例如创建一个test文件，然后退出： $docker run -it ubuntu:latest /bin/bash root@3548583db1bb:/# touch test root@3548583db1bb:/# exit 记住容器的ID为3548583db1bb。 然后使用docker images命令查看刚才创建的镜像，也可以使用docker ps -a来查看容器。 接下来使用·docker commit·命令根据容器3548583db1bb来创建一个新的镜像。 提交信为：Added a new file 作者信息为：Docker Newbee 源容器：3548583db1bb 被创建的容器的标签：test:0.1 使用docker image命令查看刚才创建的test:0.1镜像 基于本地模板导入用户可以直接从一个操作系统模板文件导入一个镜像文件，主要使用docker import命令。命令格式为 docker import [OPTIONS] file |URL| -[REPOSITORY[:TAG]] OPTIONS说明： -c：应用docker指令创建镜像文件 -m：提交信息 要直接导入一个镜像，可以使用OpenVZ提供的模板来创建，或者用其他已导出的镜像模板来创建。OPENVZ模板的下载地址为http://openvz.org/Dowload/templates/precreated 存出和载入镜像用户可以使用docker save和docker load命令来存出和载入镜像。 存出镜像docker save：将指定镜像保存成tar归档文件。 语法：docker save [OPTIONS] IMAGE [IMAGE…] OPTIONS说明： -o：输出到文件 得到了my_ubuntu.tar归档 载入镜像可以使用docker load将导出的tar文件再导入到本地文件镜像库，例如从文件my_ubuntu.tar docker load：从一个在stdin上的tar归档文件中装载镜像 OPTIONS说明： -i, --input=&quot;&quot; 从一个tar归档文件中读入，而不是从stdin中 $docker load --input my_ubuntu.tar 或 $docker load &lt; my_ubuntu.tar 上传镜像可以使用docker push命令上传镜像到仓库，默认上传到Docker Hub官方仓库（需要登录）。 命令格式为： docker push NAME[:TAG] | REGISTRY_HOST[:REGISTRY_PORT] /]NAME [:TAG] 先给需要push的镜像打上标签，因为的我用户名叫kylinxiang，所以改为kylinxiang/push_test:1.0 默认是Push到Docker Hub，所以可以看到最后push到的仓库为docker.io/kylinxiang 之后就可以在Docker Hub上面就可以查看Push的镜像]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊JPA Criteria查询中的坑]]></title>
    <url>%2F2018%2F03%2F16%2F%E8%81%8A%E8%81%8AJPA-Criteria%E6%9F%A5%E8%AF%A2%E4%B8%AD%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[聊聊JPA Criteria查询中的坑JPA Criteria查询被称作动态安全类型查询，比JPQL这种方式更加健壮。关于JPA Criteria查询在IBM社区有一篇很好的文章，这里我就不去Copy（尊重默默为社区奉献的同行兄弟），请移步https://www.ibm.com/developerworks/cn/java/j-typesafejpa/ Bug复现场景创建一个Student类，然后创建其StaticMetaModel Student_类；然后使用Critirial查询年龄大于20的Student。场景很简单，但是。。。结果很意外，让我们来看看相关配置和代码。 配置依赖配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.kylin&lt;/groupId&gt; &lt;artifactId&gt;jpa-demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;jpa-demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.0.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8 &lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; yml配置文件12345678910111213141516server: port: 8800spring: datasource: password: 123456 username: root driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/jpaadvance jpa: database-platform: mysql hibernate: ddl-auto: update show-sql: true properties: hibernate: dialect: org.hibernate.dialect.MySQL5Dialect 代码Student类代码123456789101112131415161718192021package com.kylin.jpademo.domain;import org.hibernate.annotations.GenericGenerator;import javax.persistence.*;import java.io.Serializable;@Entity@Tablepublic class Student implements Serializable &#123; private static final long serialVersionUID = -7681363673194194734L; @Id @GeneratedValue(generator = "system-uuid") @GenericGenerator(name = "system-uuid", strategy = "uuid") @Column(updatable = false, nullable = false) private String id; private String name; private int age; //geter and seter Student_类代码12345678910111213package com.kylin.jpademo.domain;import com.kylin.jpademo.domain.metamodel.Student;//重点看这里import javax.persistence.metamodel.SingularAttribute;import javax.persistence.metamodel.StaticMetamodel;@StaticMetamodel(Student.class)public class Student_ &#123; public static volatile SingularAttribute&lt;Student, String&gt; id; public static volatile SingularAttribute&lt;Student, String&gt; name; public static volatile SingularAttribute&lt;Student, Integer&gt; age;&#125; Repository接口123456789package com.kylin.jpademo.repository;import com.kylin.jpademo.domain.metamodel.Student;import java.util.List;public interface StudentRepository &#123; List&lt;Student&gt; findStudentByAgeLessThan(int age);&#125; Repository实现1234567891011121314151617181920212223242526272829303132333435package com.kylin.jpademo.repository.impl;import com.kylin.jpademo.domain.metamodel.Student;import com.kylin.jpademo.domain.Student_;import com.kylin.jpademo.repository.StudentRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Repository;import org.springframework.transaction.annotation.Transactional;import javax.persistence.EntityManager;import javax.persistence.TypedQuery;import javax.persistence.criteria.*;import java.util.List;@Transactional@Repositorypublic class StudentRepositoryImpl implements StudentRepository &#123; @Autowired EntityManager em; @Override public List&lt;Student&gt; findStudentByAgeLessThan(int age) &#123; System.out.println(age); CriteriaBuilder cb = em.getCriteriaBuilder(); CriteriaQuery&lt;Student&gt; cq = cb.createQuery(Student.class); Root&lt;Student&gt; s = cq.from(Student.class); // from ... Path&lt;Integer&gt; path = s.get(Student_.age); Predicate condition = cb.gt(path, age); // condition: attribute &gt; age cq.where(condition); // where TypedQuery&lt;Student&gt; tq = em.createQuery(cq); return tq.getResultList(); &#125;&#125; 执行findStudentByAgeLessThan方法如上图所示，报了一个NullPointerException，定位到了StudentRepositoryImpl类的这一行1Path&lt;Integer&gt; path = s.get(Student_.age); 尝试解决Debug重新运行之后，发现Student_.age变量为空，说明StaticMetaModelStudent_类并没有映射到Student类。之后我google了很多方法去解决这个问题，都没有用。但是可以确定的是一定是StaticMetaModel出了问题，因为将上面出错那一行的代码改为&quot;age&quot;之后，即：1Path&lt;Integer&gt; path = s.get(“age”); Bug解决了，但这似乎违背了Criteria查询的宗旨，就是类型安全和避免运行时错误，这里的安全类型除了指明确查询中的类型安全之外，还有就是避免使用常量。如果”age”字符串手抖写成了“aeg”，在编译时肯定是没有问题的，只有在运行时才会暴露出来，到了那个时候为时已晚。所以为了尽可能的遵循Criteria的初衷，这种方式肯定不是很好的方案，之后笔者又尝试了很多种方案，都宣告失败。于是我删掉了Student_类重新写了一次，但是这次Student和Student_位于同一包中，神奇的事情发生了，这次运行正确，并且成功查找出了年龄大于20的Student。 此时的工程结构 结果如下：123456789101112[ &#123; "id": "8a4ffa05622dcf1501622dd0aaa30003", "name": "bob", "age": 90 &#125;, &#123; "id": "8a4ffa05622dcf1501622dd0ca410004", "name": "an", "age": 30 &#125;] 结论Student和Student_必须位于同一包中。 更好的解决办法解决之后，本人始终百思不得其解，google了很多文章也没有解决。在之后的各种尝试中，发现了自动生成StaticMetaModelStudent_的方法，就是引入下面的依赖。12345&lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-jpamodelgen&lt;/artifactId&gt; &lt;version&gt;1.1.1.Final&lt;/version&gt;&lt;/dependency&gt; 此依赖可以自动创建metamodel。现在我们删除我们自行创建的12```JavaPath&lt;Integer&gt; path = s.get(Student_.age); 此时程序会出现编译错误：因为刚才删除了Student_类，肯定会出现编译问题。抛开编译问题，这里我们继续执行，如下图所示，执行成功了。那么为什么呢？总结刚才的操作，你可能会猜测是不是刚才引入的依赖自动创建了Student_呢？答案是肯定的。为了证实这一点，我们去看编译运行的结果： 自动生成的Student_代码：12345678910111213package com.kylin.jpademo.domain;import javax.persistence.metamodel.SingularAttribute;import javax.persistence.metamodel.StaticMetamodel;@StaticMetamodel(Student.class)public abstract class Student_ &#123; public static volatile SingularAttribute&lt;Student, String&gt; name; public static volatile SingularAttribute&lt;Student, String&gt; id; public static volatile SingularAttribute&lt;Student, Integer&gt; age;&#125; 执行查询，没有问题。可以看出自动生成的Student_和Student在同一包下，这也印证了刚才的做法。 结论在Criteria查询中，Model和StaticMetaModel必须位于同一包下。因为在大型项目中，会涉及到很多Model，若不想自己创建对应的StaticMetaModel，可以使用hibernate-jpamodelgen依赖，自动创建。]]></content>
      <categories>
        <category>JPA</category>
      </categories>
      <tags>
        <tag>JPA</tag>
        <tag>Java</tag>
        <tag>Criteria</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[栈ADT及其应用]]></title>
    <url>%2F2018%2F03%2F14%2F%E6%A0%88ADT%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[栈模型栈（Stack）是限制插入和删除只能在一个位子上进行的表，该位子是表的末端，叫做栈的顶（top）。对栈的基本操作有进栈（push）和出栈（pop），相当于表插入和删除最后一个元素。 栈的实现由于栈可以看作是一个表，因此任何实现表的方法都能实现栈。显然，在Java集合中，ArrayList和LinkedList都支持栈的操作，由于栈的操作都是栈顶元素，所以对于数组实现的ArrayList和链表实现的LinkedList来说都花费常数时间，因此他们并没有太大区别。但是对于代码实现来说，数组实现更加简洁，更易于理解，下面将给出栈的简单实现。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class Stack&lt;E&gt; &#123; //栈的默认大小为10 private static final int DEFAULT_VALUE_SIZE = 10; //用一个数组来存储栈的元素 private E[] elementData; //栈中元素的实际个数 private int size; //构造器，调用doClear方法初始化 public Stack() &#123; doClear(); &#125; //进栈操作 public E push(E element) &#123; //存放栈元素的数组满了，则需要对elementData扩容 if (elementData.length == size) &#123; //扩容操作 ensureCapacity(size + 1); &#125; elementData[size++] = element; return element; &#125; //出栈操作，若栈为空时出栈，则抛出数组越界异常 public E pop() &#123; if (size == 0) &#123; throw new IndexOutOfBoundsException(); &#125; return elementData[--size]; &#125; //清空栈的操作 public void clear() &#123; doClear(); &#125; //清空栈的操作 private void doClear() &#123; size = 0; ensureCapacity(DEFAULT_VALUE_SIZE); &#125; //保证在进栈的，存储栈元素的elementData数组有足够的空间 private void ensureCapacity(int minCapacity) &#123; if (size &gt; minCapacity) &#123; return; &#125; E[] old = elementData; elementData = (E[]) new Object[minCapacity]; for (int i = 0; i &lt; size; i++) &#123; elementData[i] = old[i]; &#125; &#125; //返回栈的实际元素个数 public int size() &#123; return size; &#125;&#125; 上面的代码实现了栈的基本操作，push/pop/clear。 栈的应用应用1 —— 平衡符号编译器检查程序的语法错误，但是常常由于缺少一个符号（如遗漏一个花括号）引起编译不能通过。在这种情况下，一个有用的工具就是检测是成对出现的东西。于是，一个右花括号、右方括号及右括号必然对其相应的左括号。比如[()]序列是合法的，[(])是不合法的。 通过栈，可以实现上述程序，思路如下：声明一个空栈，然后挨个读取字符，如果字符是一个开放符号（左边的符号），则将其推入栈内。如果字符是一个封闭符号（右边的符号），然后弹出栈顶元素，栈为空时报错。如果弹出的开放符号不是当前封闭符号所对应的符号，则报错。依次遍历，直到遍历完所有开放符号。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class StackApplication &#123; // 申明一个栈，用来存放开放符号 Stack&lt;Character&gt; lefts = new Stack&lt;Character&gt;(); // 申明一个数组，用来存放封闭符号 ArrayList&lt;Character&gt; rights = new ArrayList&lt;Character&gt;(); // 用来存放从控制台读取的字符数组 char[] characters; // 从控制台读取字符串，并转换成字符串 private void readCharsFromConsole() &#123; Scanner scanner = new Scanner(System.in); if (scanner.hasNext()) &#123; // 给characters数组 characters = scanner.next().toCharArray(); &#125; &#125; // 检查开放符号和封闭符号是否匹配 public boolean check() &#123; readCharsFromConsole(); // 开放符号进栈lefts，封闭符号添加到数组rights for (int i = 0; i &lt; characters.length; i++) &#123; char ch = characters[i]; if (ch == '(') &#123; lefts.push(ch); &#125; if (ch == ')') &#123; rights.add(ch); &#125; &#125; // 如果开放符号的个数不等于封闭符号的个数则报错 if (lefts.size() != rights.size()) &#123; return false; &#125; // 遍历封闭符号，如果栈lefts弹出的元素不是当前封闭元素所对应的，则返回false for (int i = 0; i &lt; rights.size(); i++) &#123; if (rights.get(i).charValue() == ')') &#123; if (lefts.pop().charValue() != '(') &#123; return false; &#125; &#125; &#125; // 最后返回true return true; &#125;&#125; 测试代码1234public static void main(String[] args) &#123; StackApplication stackApplication = new StackApplication(); System.out.println(stackApplication.check());&#125; 测试结果在控制台输入((()))，回车，结果如下图所示，返回true。 在控制台输入((())，回车，结果如下图所示，返回false。 应用二 —— 计算后缀表达式（逆波兰表达式)假设我们需要一个计算器来计算我们购物的花费，你的计算公式可能是这样的：2 * 2 + 3 * 3，如果你手上的计算器的普通计算器的话，答案为21。但是现在大多数时候我们希望使用科学计算器，它可以判定运算的优先级，科学计算器的结果为13。 我们简单地分析一下科学计算器计算上面例子的过程，首先判断优先级，乘法有限，所以依次计算2*2和#3*3并将其结果分别存储到两个临时变量A1和A2中，最后计算加法，将A1和A2求和。我们可以将这种操作写为：2 2 * 3 3 * +。这就是逆波兰表达式。 如何将2 * 2 + 3 * 3转化为2 2 * 3 3 * +，参见应用三。 计算细节如下： 首先假设有一个空栈stack，遍历后缀表达式，将数字压入栈中，直到遇到一个操作符，这个操作符的操作数为连续两次出栈的结果。 第一步：stack=[2,2]，读到一个操作符为*，于是操作数连续两次出栈的结果2和2。所以计算结果为2*2=4，将结果压入栈中，stack=[4]。 第二步：继续读入数字，直到一个操作符。stack=[4,3,3]，操作符为*，操作数为连续两次出栈的结果3和3。所以计算结果为3*3=9，将结果压入栈中，stack=[4,9]。 第三部：继续读入，下一个元素为+操作数，所以执行加法操作，操作数为连续两次出栈的结果4和9，所以计算结果为4+9=13。压栈，stack=13。到此遍历完了整个后缀表达式，最后结果就为栈顶元素13。 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class StackApplication2 &#123; // 字符数组，用来保存后缀表达式的每一个字符 private char[] postfix; // 操作数栈 Stack&lt;Integer&gt; numberStack = new Stack&lt;Integer&gt;(); // 构造器，传入一个后缀表达式字符串 public StackApplication2(String postfix) &#123; this.postfix = postfix.toCharArray(); &#125; public StackApplication2() &#123; &#125; // 判断后缀表达式中字符是否为数字 private boolean isNumeric(char ch) &#123; return (ch &gt;= '0' &amp;&amp; ch &lt;= '9') ? true : false; &#125; // 科学计算器的实现方法 public int scientificCaculator() &#123; // 两个操作数 int num1; int num2; // 遍历后缀表达式 for (int i = 0; i &lt; postfix.length; i++) &#123; char temp = postfix[i]; // 如果是数字就压栈 if (isNumeric(temp)) &#123; numberStack.push(temp - '0');// char转int &#125; else &#123; // 如果是操作符就从栈中弹出操作数并执行相关运算 num1 = numberStack.pop(); num2 = numberStack.pop(); if (temp == '+') &#123; numberStack.push(num1 + num2); &#125; else if (temp == '-') &#123; numberStack.push(num1 - num2); &#125; else if (temp == '*') &#123; numberStack.push(num1 * num2); &#125; else if (temp == '/') &#123; numberStack.push(num1 / num2); &#125; &#125; &#125; // 返回最后的栈顶元素，即结果 return numberStack.pop(); &#125;&#125; 测试代码1234public static void main(String[] args) &#123; StackApplication2 stackApplication2 = new StackApplication2(&quot;6523+8*+3+*&quot;); System.out.println(stackApplication2.scientificCaculator());&#125; 结果计算一个后缀表示花费的时间是O(N)，该算法是一个十分简单的算法。注意，当一个表达式以后缀表示给出时，我们就不用知道运算的优先级，这是一个明显的优点。 应用三- 中缀表达式转后缀表达式栈不仅仅可以用来计算后缀表达式的值，还可以用来用来讲一个标准形式的表达式（中缀表达式）转换成后缀表达式。 我们假设只有运算+,*,(,)，并且表达式合法以及使用普通的优先级法则，即括号&gt;乘&gt;加。假设中缀表示1+2*3+(4*5+6)*7,则转换后的后缀表达式为：123*+45*6+7*+。 转换方法我们需要两个数据结构，一个用来存放操作符的栈operatorStack，一个用来存放后缀表达式的字符数组postfix。遍历中缀表达式，如果读到的是一个操作数，则立即添加到postfix数组中，如果是一个操作符则相对麻烦。为了说明方便，我们将operatorStack栈中的栈顶操作符称为top，当前遍历的操作符为temp。操作符的处理规则如下： 如果栈为空，则直接将temp压入operatorStack栈中。 如果栈不为空并且temp= * 或 + 或 (，然后将temp的优先级和top比较，如果temp的优先级大于top优先级，则将temp压栈；否则，依次将栈中优先级大于或等于temp的操作符弹出，添加到postfix，直到top优先级高于temp，然后将temp压栈，但是有一个情况例外，即top=（,temp的优先级低于(时，这种情况，top不会出栈，而是将temp直接压栈。 如果读到的），则依次弹出操作符，加入postfix的末尾，直到（。 现在我们对刚才提到的例子1+2*3+(4*5+6)*7采用上面的算法依次计算： 读取到操作数1，直接添加到postfix数组中。此时，operatorStack为空，postfix=[1]。 读取到操作符+，因为此时栈为空，所以直接压栈。此时，operatorStack={+}，postfix=[1]。 读取到操作数2，直接添加到postfix数组中。此时，operatorStack={+}，postfix=[1,2]。 读取到操作符*，此时temp = *，top = +，优先级temp &gt; top，所以temp压栈。此时，operatorStack={+,*}，postfix=[1,2]。 读取到操作数3，直接添加到postfix数组中。此时，operatorStack={+,*}，postfix=[1,2,3]。 读取到操作符+，此时temp = +,top = *，优先级top&gt;=temp，所以top出栈并添加到postfix数组。此时operatorStack={+}，postfix=[1,2,3,*]，top=+，top&gt;=temp，所以top出栈并添加到postfix数组。此时operatorStack={}，postfix=[1,2,3,*,+}。此时operatorStack为空，所以temp压栈。所以此时operatorStack={+}，postfix=[1,2,3,*,+}。 读取操作符（，此时temp = (，top = +，优先级temp &gt; top，所以temp直接压栈。此时，operatorStack={+,(}，postfix=[1,2,3,*,+]。 读取操作数4，直接添加到postfix数组中。此时operatorStack={+,(}，postfix=[1,2,3*,+，4]。 读取操作符*，此时temp = *，top = (，虽然优先级top &gt;= temp，但是对于（特殊处理，不出栈。所以temp直接压栈。此时operatorStack={+,(,*}，postfix=[1,2,3,*,+,4]。 读取操作数5，直接添加到postfix数组中。此时operatorStack={+,(,*}，postfix=[1,2,3,*,+,4,5]。 读取操作符+，此时temp = +，top = *，优先级top &gt;= temp，所以top出栈并且添加到postfix数组，此时operatorStack={+,(}，postfix=[1,2,3,*,+,4,5,*],top = （，优先级temp &lt; top，temp直接压栈。此时operatorStack={+,(,+}，postfix=[1,2,3,*,+,4,5,*]。 读取操作数6，直接添加到postfix数组中。此时operatorStack={+,(,+}，postfix=[1,2,3,*,+,4,5,*,6]。 读取操作符），依次弹出栈顶操作符，直到（。此时operatorStack={+}，postfix=[1,2,3,*,+,4,5,*,6,+]。 读取操作符*，此时temp = *，top = +，优先级temp &gt; top，所以temp压栈。此时operatorStack={+,*}，postfix=[1,2,3,*,+,4,5,*,6,+]。 读取操作数7，直接添加到postfix数组中。此时operatorStack={+,*}，postfix=[1,2,3,*,+,4,5,*,6,+,7]。 依次弹出栈中剩余操作符，最终operatorStack={}，postfix=[1,2,3,*,+,4,5,*,6,+,7,*,+]。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125public class InfixToPostfix &#123; // 存放操作符的栈 private Stack&lt;Character&gt; operatorStack = new Stack&lt;Character&gt;(); // 存放后缀表达式的字符数组 private char[] postfix; // 存放中缀表达式的字符数组 private char[] infix; // 定义操作符 private static final char multiply = '*'; private static final char divide = '/'; private static final char add = '+'; private static final char substract = '-'; private static final char leftParenthesis = '('; private static final char rightParenthesis = ')'; // 构造器 public InfixToPostfix(String infix) &#123; this.infix = infix.toCharArray(); postfix = new char[infix.length()]; &#125; public InfixToPostfix() &#123; &#125; // 判断一个字符是否为数字 private boolean isNumeric(char ch) &#123; return (ch &gt;= '0' &amp;&amp; ch &lt;= '9') ? true : false; &#125; private String infixToPostfix() &#123; // 插入后缀的表达式下标 int insertIndex = 0; // 操作符栈的大小 int size; // 返回结果，后缀表达式字符串 String result; for (int i = 0; i &lt; infix.length; i++) &#123; if (isNumeric(infix[i])) &#123; postfix[insertIndex++] = infix[i]; &#125; else &#123; char temp = infix[i]; size = operatorStack.size(); // 如果栈为空，就直接压栈 if (size == 0) &#123; operatorStack.push(temp); &#125; else &#123; // 栈不为空时 // 弹出栈顶元素 char top = operatorStack.pop(); if (temp == rightParenthesis) &#123; while (top != leftParenthesis) &#123; postfix[insertIndex++] = top; top = operatorStack.pop(); &#125; &#125; else &#123; // 如果当前操作符的优先级大于栈顶操作符的优先级，则当前操作符进栈 if (operatorPriorityCompare(temp, top)) &#123; /* * 因为上一行为了比较当前操作符和栈顶元素的操作符, * 上面弹出了栈顶元素, * 所以这里要先将弹出的操作符压栈 */ operatorStack.push(top); &#125; /* * 如果当前操作符的优先级低于或等于栈顶操作符的优先级， 则栈顶操作符出栈，然后一直比较， * 直到栈顶操作符优先级大于当前操作符或栈为空，然后当前操作符进栈。 */ while (!operatorPriorityCompare(temp, top)) &#123; if (top == leftParenthesis) &#123; operatorStack.push(top); break; &#125; else &#123; postfix[insertIndex++] = top; size = operatorStack.size(); if (size == 0) &#123; break; &#125; top = operatorStack.pop(); &#125; &#125; // 当前操作符进栈 operatorStack.push(temp); &#125; &#125; &#125; &#125; // 遍历完毕，一次弹出栈中剩余操作符 size = operatorStack.size(); if (size != 0) &#123; for (int i = 0; i &lt; size; i++) &#123; postfix[insertIndex++] = operatorStack.pop(); &#125; &#125; result = String.valueOf(postfix).trim(); return result; &#125; // 判断操作符的优先级：括号&gt;乘除&gt;加减 // true: temp&gt;top false: top &gt;= temp private boolean operatorPriorityCompare(char current, char top) &#123; if (((current == multiply || current == divide) &amp;&amp; (top == substract || top == add)) || (current == leftParenthesis &amp;&amp; (top == multiply || top == divide || top == substract || top == add))) &#123; return true; &#125; else &#123; return false; &#125; &#125;&#125; 测试代码12345public static void main(String[] args) &#123; InfixToPostfix infixToPostfix = new InfixToPostfix("1+2*3+(4*5+6)*7"); String result = infixToPostfix.infixToPostfix(); System.out.println(result);&#125; 测试结果与上面相同，这种转换需要O(N)时间。可以通过制定减法和加法有相同优先级以及乘法和除法有相同优先级二将减法和乘法添加到指令中去。需要注意的是，表达式a-b-c应该转化为ab-c-，而不是abc–。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树(binary tree)]]></title>
    <url>%2F2018%2F03%2F14%2F%E4%BA%8C%E5%8F%89%E6%A0%91-binary-tree%2F</url>
    <content type="text"><![CDATA[二叉树的定义二叉树是n(n&gt;=0)个具有相同类型的元素的有限集合，当n=0时称为空二叉树，当n&gt;0时，数据元素被分为一个称为根（Root）的数据元素及两棵分别为左子树和右子树的数据元素的集合，左、右子树互不相交，且左、右子树都为二叉树。在二叉树中，一个元素也称为一个节点。 二叉树的子树是有序的，即若将其左、右子树颠倒，就将成为另一棵不同的二叉树。即使树中的节点只有一棵子树，也要明确指出其是左子树还是右子树。由于左、右子树的有序以及二叉树可以为空，因此，二叉树具有以下五种基本形态，即空二叉树、仅有根节点的二叉树、右子树为空的二叉树、左子树为空的二叉树、左右子树均为非空的二叉树，如下图所示： 二叉树的基本概念 节点的度：节点所拥有子树的个数称为该节点的度。 叶子：度为0的节点称为叶子。 孩子：节点子树的根，称为该节点的孩子。二叉树中，孩子有左右之分，分别为左孩子和右孩子。 双亲：孩子节点的上层节点都称为该节点的双亲。 以某节点的根的子树中的除根节点之外的任意一个节点都称为该节点的子孙。 祖先：节点的祖先是从根到该节点所经分支上的所有节点。 节点的层次：从根节点起，跟为第一层，他的孩子为第二层，孩子的孩子为第三层，依次类推，即某个节点的层次为L层，那么他的孩子节点的层数为L+1层。 兄弟：同一双亲的孩子互为兄弟。 堂兄弟：其双亲在同一层的节点互为堂兄弟。 二叉树的度：二叉树中最大的节点度称为二叉树的度。 二叉树的深度：二叉树中节点的最大层次书被称为二叉树的深度。 满二叉树：在一棵二叉树中，所有分支节点都存在左子树和右子树，并且所有叶子节点都在同一层上，这样的二叉树被称为满二叉树。 完全二叉树：对深度为k的满二叉树中的节点从上至下、从左至右从1开始编号。对一棵具有n个节点、深度为k的二叉树，采用的同样的办法对树中的节点从上至下，从左至右从1开始连续编号，如果编号为i（i&lt;=n）的节点与满二叉树中编号为i的节点在同一位置，则称此二叉树为完全二叉树。对于一棵完全二叉树，其叶子节点只可能出现在最下层和倒数第二层，而最下层的叶子集中在树的最左部。 二叉树的性质 一棵非空二叉树的第i层最多有2^(i-1)个节点。 深度为k的二叉树至多有2^k-1个节点。 对任何一棵二叉树T，如果叶子节点数为n0，度为2的节点数为n2，那么n0=n2+1。 具有n个节点的安全二叉树的深度k=log2N+1（这里解释一下，k=以2为底N的对数向下取整+1）。 对一棵具有n个节点的完全二叉树的从上至下，从左至右从1开始连续编号，那么对任意一个节点i有：如果i=1,则节点i是二叉树的根，无双亲；如果i&gt;1，则其双亲是i/2向下取整。如果2i&gt;n，则节点无左孩子，为叶子节点；如果2i&lt;n，则其左孩子是2i。如果2i+1&gt;n，则节点i无右孩子；如果2i+1&lt;=n，则其右孩子为2i+1。 二叉树的存储结构顺序存储完全二叉树的顺序存储我们先看以下完全二叉树的顺序存储。要存储一棵完全二叉树，不仅需要二叉树的节点数据，还需要存储它的结构信息，即双亲和孩子关系信息。从上面的性质5可以看出，完全二叉树中节点i的左孩子为2i，右孩子为2i+1，双亲为i/2向下取整。因此，如果将完全二叉树从上至下，从左至右从1开始编号，把编号为i的节点放在线性存储单元的第i个位子，那么其左孩子存储在2i位子，右孩子存储在2i+1位子，则孩子和双亲的关系就体现出来了。一般二叉树的顺序存储对于一般二叉树而言，如果把它的节点按照从上至下、从左至右从1开始连续编号存储在一维的存储单元，那么无法反应其节点间的双亲孩子关系，即不能反映二叉树的结构关系，怎么办呢?可以把一般的二叉树补成一棵完全二叉树，这样，它就可以按照完全二叉树的顺序存储方式存储了，只是新补上去的节点只占位子，不存放节点数据。如下图所示： 对于一般二叉树，需要增加一些节点才能存储此二叉树的节点数据和结构关系，这样可能会造成存储空间的浪费，例如，对于深度为3的右偏斜二叉树，需要额外增加4个存储单位。当二叉树的深度更深时，则需要更多的节点，例如当深度为100的右偏斜二叉树，需要2^100-101个额外空间，为了采用顺序存储方式来存储此二叉树，把全世界所有计算机的存储空间加起来也不够！因此很有必要采用其他形式的存储方式。 链式存储链表可以用来表示一维的线性结构，也可以用来表示非线性的二叉树结构。二叉树的链式存储结构常有二叉链表存储、三叉链表存储及线索链表。二叉链表中有两个指针域，分别指向其左、右孩子；三叉链表中除了指向其左、右孩子的指针域外，还有指向其双亲的指针域；线索链表是为了反映节点的前驱、后继而将二叉链表中空指针指向其前驱或后继而形成的链式存储结构。 二叉链表存储链表中每一个节点包含3个域：数据域、左孩子指针域、右孩子指针域。左、右孩子指针域分别指向左孩子和右孩子的存储地址。 二叉链表存储代码实现12345678910111213141516171819202122232425262728293031323334353637383940public class BinaryTreeNode&lt;T&gt; &#123; private T data; private BinaryTreeNode&lt;T&gt; leftChild; private BinaryTreeNode&lt;T&gt; rightChild; public BinaryTreeNode(T data) &#123; this(data, null, null); &#125; public BinaryTreeNode(T data, BinaryTreeNode&lt;T&gt; leftChild, BinaryTreeNode&lt;T&gt; rightChild) &#123; this.leftChild = leftChild; this.rightChild = rightChild; this.data = data; &#125; public T getData() &#123; return data; &#125; public void setData(T data) &#123; this.data = data; &#125; public BinaryTreeNode&lt;T&gt; getLeftChild() &#123; return leftChild; &#125; public void setLeftChild(BinaryTreeNode&lt;T&gt; leftChild) &#123; this.leftChild = leftChild; &#125; public BinaryTreeNode&lt;T&gt; getRightChild() &#123; return rightChild; &#125; public void setRightChild(BinaryTreeNode&lt;T&gt; rightChild) &#123; this.rightChild = rightChild; &#125;&#125; 三叉链表存储在三叉链表中，除根节点的parent域为空外，其余节点的parent域都不为空，指向其双亲。因此在三叉链表中，查找孩子和双亲都是很快捷的，但是增加了一些额外空间开销。 三叉链表存储实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class BinaryTreeNode3&lt;T&gt; &#123; private T data; private BinaryTreeNode3&lt;T&gt; leftChild; private BinaryTreeNode3&lt;T&gt; parent; private BinaryTreeNode3&lt;T&gt; rightChild; // 叶子节点构造器 public BinaryTreeNode3(T data, BinaryTreeNode3&lt;T&gt; parent) &#123; this(data, null, parent, null); &#125; // 一般节点构造器 public BinaryTreeNode3(T data, BinaryTreeNode3&lt;T&gt; leftChild, BinaryTreeNode3&lt;T&gt; parent, BinaryTreeNode3&lt;T&gt; rightChild) &#123; this.leftChild = leftChild; this.parent = parent; this.rightChild = rightChild; this.data = data; &#125; public T getData() &#123; return data; &#125; public void setData(T data) &#123; this.data = data; &#125; public BinaryTreeNode3&lt;T&gt; getLeftChild() &#123; return leftChild; &#125; public void setLeftChild(BinaryTreeNode3&lt;T&gt; leftChild) &#123; this.leftChild = leftChild; &#125; public BinaryTreeNode3&lt;T&gt; getParent() &#123; return parent; &#125; public void setParent(BinaryTreeNode3&lt;T&gt; parent) &#123; this.parent = parent; &#125; public BinaryTreeNode3&lt;T&gt; getRightChild() &#123; return rightChild; &#125; public void setRightChild(BinaryTreeNode3&lt;T&gt; rightChild) &#123; this.rightChild = rightChild; &#125;&#125; 二叉树的遍历先序、中序、后续的递归遍历例子 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class BinaryTree&lt;T&gt; &#123; public BinaryTree() &#123; // ... &#125; // 访问数据 public void visitData(BinaryTreeNode&lt;T&gt; node) &#123; System.out.print(node.getData() + " "); &#125; // 前序遍历 public void preOrder(BinaryTreeNode&lt;T&gt; node) &#123; if (null != node) &#123; visitData(node); preOrder(node.getLeftChild()); preOrder(node.getRightChild()); &#125; &#125; // 中序遍历 public void inOrder(BinaryTreeNode&lt;T&gt; node) &#123; if (null != node) &#123; inOrder(node.getLeftChild()); visitData(node); inOrder(node.getRightChild()); &#125; &#125; // 后续遍历 public void postOrder(BinaryTreeNode&lt;T&gt; node) &#123; if (null != node) &#123; postOrder(node.getLeftChild()); postOrder(node.getRightChild()); visitData(node); &#125; &#125; public static void main(String[] args) &#123; BinaryTreeNode&lt;String&gt; g = new BinaryTreeNode&lt;String&gt;("g"); BinaryTreeNode&lt;String&gt; c = new BinaryTreeNode&lt;String&gt;("c"); BinaryTreeNode&lt;String&gt; d = new BinaryTreeNode&lt;String&gt;("d"); BinaryTreeNode&lt;String&gt; b = new BinaryTreeNode&lt;String&gt;("b", c, d); BinaryTreeNode&lt;String&gt; f = new BinaryTreeNode&lt;String&gt;("f", g, null); BinaryTreeNode&lt;String&gt; e = new BinaryTreeNode&lt;String&gt;("e", null, f); BinaryTreeNode&lt;String&gt; a = new BinaryTreeNode&lt;String&gt;("a", b, e); BinaryTree&lt;String&gt; binaryTree = new BinaryTree&lt;String&gt;(); System.out.print("preOder:"); binaryTree.preOrder(a); System.out.println(); System.out.print("inOder:"); binaryTree.inOrder(a); System.out.println(); System.out.print("postOder:"); binaryTree.postOrder(a); System.out.println(); &#125;&#125; 执行结果 非递归遍历的思想当非递归遍历时，我们需要从根节点开始，从左到右深入到每一个叶子。当深入到一个叶子节点时，需要返回到其父节点，然后去深入其他分支。可以看出深入和返回是一对相反的操作，所以可以用到数据结构 栈来保存深入节点时树的结构关系。至于该遍历是先序、中序或是后序，这只取决于其访问 非递归的中序遍历沿左子树深入时，深入一个节点入栈一个节点，沿左分支无法继续深入时（某个节点无左孩子），出栈，出站时同时访问节点数据，然后从该节点的右子树继续沿左子树深入，这样一直下去，最后从根节点的右子树返回时结束。123456789101112131415161718192021222324// 非递归的中序遍历public void nrInOrder(BinaryTreeNode&lt;T&gt; root) &#123; // 声明一个栈 Stack&lt;BinaryTreeNode&lt;T&gt;&gt; stack = new Stack&lt;BinaryTreeNode&lt;T&gt;&gt;(); // 当前节点 BinaryTreeNode&lt;T&gt; p = root; // 当节点和栈不同时为空时 while (!(p == null &amp;&amp; stack.isEmpty())) &#123; // 遍历p节点下的所有左孩子 while (p != null) &#123; // 将左孩子压栈 stack.push(p); p = p.getLeftChild(); &#125; if (stack.isEmpty()) &#123; return; &#125; else &#123; p = stack.pop();// 出栈 visitData(p);// 出栈时访问数据 p = p.getRightChild();// 指向右孩子 &#125; &#125;&#125; 非递归的层次遍历从根节点开始，根节点入队，访问其数据，然后根节点的左右孩子入队，根节点出队。此时相当于第一层遍历完毕。第二层数据已经入队。然后当前队首元素出队，访问数据，加入当前元素的左右孩子，依次类推直到队列为空。123456789101112131415161718192021222324252627public void levelOrder(BinaryTreeNode&lt;T&gt; root) &#123; // 声明一个队列 Queue&lt;BinaryTreeNode&lt;T&gt;&gt; queue = new LinkedList&lt;BinaryTreeNode&lt;T&gt;&gt;(); // 如果二叉树为空，直接返回 if (null == root) &#123; return; &#125; // 根节点入队 queue.add(root); // 临时变量，用来保存上一次出队的元素 BinaryTreeNode&lt;T&gt; temp; // 遍历队列，直到队列为空 while (!queue.isEmpty()) &#123; // 出队 temp = queue.remove(); // 访问刚才出队元素的数据 visitData(temp); // 若刚才出队的元素（节点）有左孩子，则左孩子入队 if (null != temp.getLeftChild()) &#123; queue.add(temp.getLeftChild()); &#125; // 若刚才出队的元素（节点）有左孩子，则左孩子入队 if (null != temp.getRightChild()) &#123; queue.add(temp.getRightChild()); &#125; &#125; &#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Docker搭建Redis主从复制、哨兵机制]]></title>
    <url>%2F2018%2F03%2F14%2F%E4%BD%BF%E7%94%A8Docker%E6%90%AD%E5%BB%BARedis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E3%80%81%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[拓扑结构本文搭建如下图所示的redis拓扑结构，拓扑中共有3个哨兵，1和mater结点和2个slave结点。拓扑信息： 角色 ip port redis-master redis-master或者master或者master-sentinel或者master-sentinel2或者master-sentinel3或自动分配的ip 6379 redis-slave1 容器启动时自动分配的ip 6380 redis-slave2 容器启动时自动分配的ip 6381 redis-master-sentinel 容器启动时自动分配的ip 26379 redis-master-sentinel2 容器启动时自动分配的ip 26380 redis-master-sentinel3 容器启动时自动分配的ip 26381 注：master或者master-sentinel或者master-sentinel2或者master-sentinel3都是主节点容器的别名。与之相关联的容器可以通过别称来代替ip访问容器。 搭建主从复制结构master节点配置master节点配置文件 master节点配置文件详解 port：端口号 daemonize：redis采用的是单进程多线程的模式。当redis.conf中选项daemonize设置成yes时，代表开启守护进程模式。在该模式下，redis会在后台运行，并将进程pid号写入至redis.conf选项pidfile设置的文件中，此时redis将一直运行，除非手动kill该进程。 logfile：日志文件的名字，在工作目录下自动创建，会记录redis的运行日志。 dbfilename：dump文件的名字，在工作目录下自动创建。 dir：工作目录的路径。 其他配置请参考redis中文官网：www.redis.cn 在docker中运行redis master节点服务命令说明： --name: 命名容器为redis-master，一定不要忽略容器命名，为后面--link命令命名更容易记住名字。 -v:将本地的配置文件~/redis/redis-6379.conf挂载到容器中的/redis/redis-6379.conf 容器启动后，进入容器挂载的目录，执行redis-server redis-6379.conf命令，使用redis-6379.conf配置启动redis服务。具体操作如下图所示：执行上述命令之后，如果没有消息，那么就是最好的消息，说明redis-server已经成功启动了。可以通过redis-6379.conf中配置的日志文件来查看启动情况。具体操作如下图所示：日志说明： 第一行：redis正在启动 第二行：redis版本信息，64位，进程号等 第三行：加载配置 第四行：redis的运行模式为standalone，端口为6379 第五行：警告，这句话的翻译大概就是：对一个高负载的环境来说tcp设置128这个值，太小了。具体解决方案参考：https://www.cnblogs.com/faunjoe88/p/7158484.html 第六行：说明redis server已经成功初始化 第七行： 警告，THP的系统配置问题，具体参考：https://jingyan.baidu.com/article/da1091fb196ea7027849d6b0.html上述警告对于demo来说可以忽略，但是对于生产环境，需要重新对系统进行相关配置之后，再重新启动容器。 至此，master节点已经成功启动了。 slave节点配置slave节点配置文件两个slave节点的配置一模一样，除了端口号之外。slave1的端口为6380，slave2的端口号为6381。 slave节点配置文件详解 前5项配置和master节点类似，请参考master节点配置说明。 这里重点说一下 slaveof命令，此命令用来给当前redis server节点指定一个master节点，自身作为master节点的slave节点。slaveof命令的格式为slaveof &lt;ip&gt; &lt;port&gt;，很明显，当前节点通过ip和port来定位将哪一个节点作为master节点，但是对于配置slaveof redis-master 6379来说，redis-master参数并不是一个ip。这里是因为在docker环境下，容器启动是ip是不定的，所以容器的通信可以通过--link选项来实现，而这里的redis-master就是master节点容器的名字，用容器名可以代替ip。具体参看下文。 在docker中运行redis slave节点服务命令说明： --name: 容器名为redis-slave1 -v: 将本地~/redis/redis-6380.conf挂载到容器目录/redis/redis-6380.conf --link: 建立与master节点之间的容器间的通信，redis-master为master节点的容器名，master为redis-master的别名。因此，slave的配置文件redis-6380.conf中最后一项配置也可以配置为slaveof master 6379。 容器启动后使用redis-server redis-6380.conf命令启动redis server服务。如下图所示：redis-server redis-6380.conf命令执行后，如果没有任何消息，那么就是最好的消息，说明redis server已经成功启动。下面可以通过查看日志文件来查看启动情况。如下图所示：日志分析： 从第二行可以看出redis-server已经启动成功了。 Connecting to MASTER redis-master:6379说明已经连接到master节点，并且开始了数据的同步，从master节点复制到slave节点。 从最后6行可以看出，因为是新增的slave结点，所以master到slave的复制时全量复制（倒数第五行），部分复制不可用（倒数第六行）。复制一共经历了四个步骤（最后四行）：1. 从master接收数据 2.清理掉旧的数据 3.在内存中接在db 4.复制成功。 配置redis哨兵redis哨兵配置文件配置说明： port daemonize logfile dir配置和普通redis server节点相同。 sentinel monitor：该命令的格式为sentinel monitor &lt;master&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt;。&lt;master&gt;：参数为哨兵监控的master节点的别名&lt;ip&gt;：参数为监控的master节点的ip（在docker中，容器间用--link命令通信，所以可以替换为目标容器的名字或别名）&lt;port&gt;：为监控的master结点的端口&lt;quorum&gt;：代表要判定master节点最终不可达所需要的票数。用于故障发现和判定。例如如果将quorum配置为2，代表至少要两个哨兵节点认为master节点不可达，那么这个不可达的判定才是客观的，对于值设置的越小，那么达到下线的条件就越宽松，反之越严格。一般建议将其设置为哨兵节点的数量加1。 sentinel down-after-milliseconds命令格式为sentinel down-after-milliseconds &lt;master-name&gt; &lt;times&gt;&lt;master&gt;：参数为主节点的名称，这里为上面设置的mymaster&lt;times&gt;：sentinel节点定期会想master节点发送ping命令，如果超过times毫秒没有收到回复，则判定该节点不可达。down-after-milliseconds虽然以为参数，但实际上对哨兵节点、主节点、从节点的判定同时有效，可以通过主节点来获取从节点和哨兵节点的信息。 sentinel parallel-syncs格式为sentinel parallel-syncs &lt;master-name&gt; &lt;nums&gt;当哨兵节点集合对主节点的故障判定达到一致时，哨兵领导节点会做故障转移操作，选出新的主节点，原来的从节点会向新的主节点发起复制操作，parallel-syncs参数就是限制从节点向新的主节点发起复制的个数。若发起复制的从节点过多，那么可能会造成主节点阻塞。若发起复制的从节点过少，可能会造成数据在复制期间不一致的情况。 sentinel failover-timeout 格式为sentinel failover-timeout &lt;master-name&gt; &lt;times&gt;表示故障转移的超时时间。其他配置请参加redis中文官网：www.redis.cn 在docker容器中启动redis哨兵服务使用下图命令在容器中启动redis哨兵服务。其他两个哨兵服务只需要修改：--name参数（比如 redis-master-sentinel2)-v挂载相应的配置文件(比如~/redis/redis-26380.conf:/redis/redis-62380.conf)，–link参数给主节点去不同的别名(比如redis-master:master-sentinel2)。在容器中启动redis-sentinel服务：运行上述命令后没有消息，就是最好的消息。下面可以查看工作目录下的日志文件来查看启动情况。如下图所示：日志说明： 从第四行可以看出，节点启动成功，以sentinel模式运行，端口为26379。 倒数第二行为sentinel的id信息 最后一行说明新加了一个哨兵节点监控到master节点，名字为mymaster，ip为172.17.0.2，quorum为2。 至此，redis-sentinel节点配置完毕，其余两个sentinel节点请读者根据上面配置自行配置完成（很容易）。 总结本文从配置角度描述了怎么使用Docker搭建redis主从复制，并且添加了哨兵机制，但是并没有对redis进行详细剖析，这里强烈建议读者阅读相关书籍或是到redis官网了解redis运行机制。若有问题，欢迎在评论区留言。本文会定期更新，以便使用跟新版本的redis和docker。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
</search>
